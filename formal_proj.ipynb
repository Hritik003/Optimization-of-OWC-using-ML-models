{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhWtCrq1G84p",
        "outputId": "2ca7b98c-1ad9-4d71-d461-878982924e73"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Data_simple_OWC.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1D, MaxPooling1D, Flatten, Dense\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load your dataset\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/Data_simple_OWC.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[1;32m     12\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_OWC\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Data_simple_OWC.csv'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/Data_simple_OWC.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('P_OWC', axis=1).values\n",
        "y = data['P_OWC'].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(X_test_reshaped, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGUMhIVYHeBJ",
        "outputId": "571e85ba-ef47-4762-e635-7c355475ace1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72/72 [==============================] - 0s 848us/step\n",
            "18/18 [==============================] - 0s 1ms/step\n",
            "Training MSE: 25526962.965807036\n",
            "Testing MSE: 25603563.37846604\n",
            "Training R-squared: 0.03372160048388728\n",
            "Testing R-squared: 0.018191196822162414\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train_reshaped)\n",
        "y_test_pred = model.predict(X_test_reshaped)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2_score_train = r2_score(y_train, y_train_pred)\n",
        "r2_score_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Training MSE: {mse_train}\")\n",
        "print(f\"Testing MSE: {mse_test}\")\n",
        "print(f\"Training R-squared: {r2_score_train}\")\n",
        "print(f\"Testing R-squared: {r2_score_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxTzd1arIjvA"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAIIDKaKHe0x",
        "outputId": "bb6075df-cf67-44aa-a12a-af40667c45ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 1499821.9140040844\n",
            "Root Mean Squared Error (RMSE): 1224.672165930166\n",
            "R-squared (R²): 0.9424869758712286\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "m\n",
        "random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'R-squared (R²): {r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "MtmcSMy3zj65",
        "outputId": "61ee8839-d4b4-46dd-a72c-615108fde2dd"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d6be8636e92f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ],
      "source": [
        "plt(y_pred,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-9hpKfKypj0",
        "outputId": "5beaa93a-a944-4a49-8698-73466a0ef2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 2, 64)             192       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 1, 64)             0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4417 (17.25 KB)\n",
            "Trainable params: 4417 (17.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "WwlIdzbCzBpE",
        "outputId": "99cc5f81-ee8c-4a3b-b3e9-f7197cc35297"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'RandomForestRegressor' object has no attribute 'summary'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b9c523078d9c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_forest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'summary'"
          ]
        }
      ],
      "source": [
        "random_forest_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urtBWHM2IdBh",
        "outputId": "a85d175f-256b-4e03-e8e4-9cfa9b8a9b2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_base.py:174: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:189: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with configuration: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Testing configuration: 6 layers, 16 neurons, gelu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'gelu' instead.\n",
            "Testing configuration: 6 layers, 16 neurons, elu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'elu' instead.\n",
            "Testing configuration: 6 layers, 16 neurons, selu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'selu' instead.\n",
            "Testing configuration: 6 layers, 32 neurons, relu activation, sgd solver\n",
            "Testing configuration: 6 layers, 32 neurons, gelu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'gelu' instead.\n",
            "Testing configuration: 6 layers, 32 neurons, elu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'elu' instead.\n",
            "Testing configuration: 6 layers, 32 neurons, selu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'selu' instead.\n",
            "Testing configuration: 6 layers, 64 neurons, relu activation, sgd solver\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:189: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with configuration: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Testing configuration: 6 layers, 64 neurons, gelu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'gelu' instead.\n",
            "Testing configuration: 6 layers, 64 neurons, elu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'elu' instead.\n",
            "Testing configuration: 6 layers, 64 neurons, selu activation, sgd solver\n",
            "Error with configuration: The 'activation' parameter of MLPRegressor must be a str among {'relu', 'identity', 'tanh', 'logistic'}. Got 'selu' instead.\n",
            "Testing configuration: 6 layers, 128 neurons, relu activation, sgd solver\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the parameter space\n",
        "hidden_layers = [5, 6, 7, 8, 9, 10]\n",
        "neurons = [16, 32, 64, 128, 256, 512, 1024]\n",
        "activations = ['relu', 'gelu', 'elu', 'selu']\n",
        "solvers = ['sgd', 'rmsprop', 'adagrad']\n",
        "\n",
        "\n",
        "best_model = None\n",
        "best_rmse = float('inf')\n",
        "best_config = {}\n",
        "\n",
        "for h in hidden_layers:\n",
        "    for n in neurons:\n",
        "        for activation in activations:\n",
        "            for solver in solvers:\n",
        "                if solver == 'rmsprop' or solver == 'adagrad':\n",
        "\n",
        "                    continue\n",
        "                print(f\"Testing configuration: {h} layers, {n} neurons, {activation} activation, {solver} solver\")\n",
        "\n",
        "                hidden_layer_sizes = tuple([n] * h)\n",
        "\n",
        "                try:\n",
        "\n",
        "                    mlp = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes,\n",
        "                                       activation=activation,\n",
        "                                       solver=solver,\n",
        "                                       max_iter=1000,\n",
        "                                       random_state=42)\n",
        "                    mlp.fit(X_train_scaled, y_train)\n",
        "\n",
        "                    y_pred = mlp.predict(X_test_scaled)\n",
        "                    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "                    if rmse < best_rmse:\n",
        "                        best_rmse = rmse\n",
        "                        best_model = mlp\n",
        "                        best_config = {'hidden_layers': h, 'neurons': n, 'activation': activation, 'solver': solver}\n",
        "                except ValueError as e:\n",
        "                    print(f\"Error with configuration: {e}\")\n",
        "                    continue\n",
        "\n",
        "print(f\"Best RMSE: {best_rmse}\")\n",
        "print(f\"Best configuration: {best_config}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vo-5p_rJakR"
      },
      "outputs": [],
      "source": [
        "Number of hidden layer { 5, 6, 7, 8, 9, 10 }\n",
        "Number neurons in each hidden layer { 16, 32, 64, 128, 256, 512, 1024}\n",
        "Activation function in each of the hidden layer { ReLU, GELU, ELU, SELU }\n",
        "Optimization function of the MLP model { SGD, RMSPROP, ADAGRAD,"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
